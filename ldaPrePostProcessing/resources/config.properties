# Path to top folder of the Reuters document collection containing the xml- articles
CorpusPath = /home/stefan/Documents/AI/project_2/data/Reuters/Original Files/Reuters Corpus Volume 1 (RCV1) - Disk 1 of 2/0809

# NER categories to exclude during vocabulary generation
NERExclusionCategories = DATE,DURATION,MONEY,NUMBER,ORDINAL,PERCENT,TIME,SET
# stopword file for vocabulary generation, textfile with one word per line
StopwordsFile = /home/stefan/Documents/AI/project_2/data/important/stopwords.txt
# dictionary file for vocabulary generation, textfile with one word per line
DictionaryFile = /home/stefan/Documents/AI/project_2/data/important/hunspell_dict.txt

# output directory for final or intermediate results
ResultDir = /home/stefan/Documents/AI/project_2/data/extractions_09/processed_0809

# base part of vocabuary file name, will be placed in ResultDir
VocabularyFilenameBase = voc
# base part of lda / dtm input files, will be placed in ResultDir
DataFilenameBase = rcv1

# filename for Reuters metadata output, will be placed in ResultDir
MetaDataFilename = metadata.txt
# lda output file describing the topic distributions for each document (gamma file), read from ResultDir
TopicsPerDocsFilename = ldaTopicsPerDocFull.txt
# lda output file describing the word distributions for each topic (beta file), read from ResultDir
WordsPerTopicsFilename = dtmTopics.txt

# number of dtm timesteps
NumTimesteps = 6

# topic change similarity threshold
SimilarityTreshold = 0.01

# number of top words evaluated for each topic
NumTopWords = 20
# number of top documents evaluated for each topic
NumTopDocs = 20

# output of lda postprocessing
OutDocsPerTopicFilename = topicTopDocs.txt
OutWordsPerTopicFilename = topics.dat
OutTopicScoresPeTimestepFilename = topicScores.txt
OutVisDataFilename = dataset.dat
