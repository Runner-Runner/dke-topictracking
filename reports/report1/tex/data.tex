\section{Reuters Corpus}\label{sec:Corpus}
The main task is to perform topic detection on news articles. For this purpose, the group was given the Reuters Corpus RCV1 containing news articles from the 1996-08-20 to the 1997-08-19.

\subsection{Given Data}\label{sec:Given}
All articles for one day of the year are grouped in a ZIP-archive each. The articles themselves are in XML-format, meaning the important parts are present as XML-attributes. By parsing these XML-documents and querying the contained attributes, information can be gathered about the headline, author, the article itself, the country code, the date and the ID of the article to name the most important ones. Furthermore, there is an Excel file in the Corpus, that lists additional attributes for each article. Most of these are empty, but in some cases additional information can be found out, like the city, continent and day.

\subsection{Webcrawler}\label{sec:Webcrawler}
Aside from the RCV1, there is an RCV2 available, that contains articles in 13 different languages for the same period as the RCV1. Furthermore, there is a TRC2, containing the articles between 2008-01-01 and 2009-02-28\footnote{http://trec.nist.gov/data/reuters/reuters.html}. Since that data is at least 7 years old (as of March 2016), an option for the project is to generate a custom Corpus for research purposes. Reuters offers a news archive, where all news articles can be viewed sorted by date\footnote{http://www.reuters.com/resources/archive/us/}. A Webcrawler was programmed, that crawls through the articles of a certain day, month, or year and automatically downloads the HTML file associated with each article. The tool furthermore offers to format each article and generate a TXT-document, that contains all important information about the article, which is the URL, time, headline, description, contents and tags.

\section{Visualization}\label{sec:Visualization}
The final part of the project and the most important one after the topic detection itself is a good visualization of the result data, so it becomes easier for humans to understand what to make of the results and how to interpret the data. The goal here is to find a cross-platform solution, which can be realized by using a JavaScript-library for visualization, so the visualization can be used on any system in a webbrowser. The initial plan here is to use a stacked graph on a timeline, with the topic percentages present for each day in relation to the number of entries altogether and see, if that is a clear enough solution. Interactiveness can be added by allowing to select for example a specific range on the timeline. An appropriate library that seems to offer all the features needed is called Rickshaw\footnote{http://code.shutterstock.com/rickshaw/}. 