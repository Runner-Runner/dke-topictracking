\subsection{Preprocessing}

For our purpose a lot of documents will be processed. These articles are written by different authors with different writing styles. On top of that, the following information extraction algorithms deal with occurrences of words (Bag-of-words model). Words have to be spelled correctly and consistent (for example, considering different spellings in British and American English) and should be reduced to stem-form, so that these algorithms are able to categorize them properly. Transfers to lower case letters, elimination of apostrophes and stemming are examples for text normalization. Some frameworks might already include these steps. \cite{Grobelnik}
\\
\\
Also on the semantic level there might be some preprocessing steps dealing with synonyms, homonyms, hyponymy and polysemy \cite{Grobelnik}. Depending on the nature of documents being evaluated, preprocessing might have only little influence on the final results, which has to be taken into consideration when putting work into implementing preprocessing steps.